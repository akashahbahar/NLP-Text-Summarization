{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwFgRKDDsE1HclmjLXU/7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashahbahar/NLP-Text-Summarization/blob/main/TEXT_SUMMARIZATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_news(filename):\n",
        "    with open(filename) as f:\n",
        "        text = f.read();\n",
        "    print(\"News details:\");\n",
        "    print(\"Text Length: \", str(len(text)));\n",
        "    return text;"
      ],
      "metadata": {
        "id": "T2QrLL0_Lwbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = read_news('sample_news.txt');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "hcCVI25lMizv",
        "outputId": "056fe4e9-d7c2-4f86-907f-db15c830136a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c52e0bcd8741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_news\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UTMnews2.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-e4df88958d6b>\u001b[0m in \u001b[0;36mread_news\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_news\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"News details:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Text Length: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'UTMnews2.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize;\n",
        "import nltk;\n",
        "import numpy as np;\n",
        "from nltk import word_tokenize;\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoXh8J8nZkFY",
        "outputId": "c81f59d0-782a-43bf-ac5d-283fabdf1385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#class Text_summarizer:\n",
        "def tokenize_sentence(text):\n",
        "    return sent_tokenize(text);"
      ],
      "metadata": {
        "id": "0e1Ac00aZUHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mapping_wordtoidx(doc_list):\n",
        "    current_index = 0;\n",
        "    wordtoidx_dict = {};\n",
        "\n",
        "    for doc in doc_list:\n",
        "        tokens = word_tokenize(doc.lower());\n",
        "        for token in tokens:\n",
        "            if token not in wordtoidx_dict:\n",
        "                wordtoidx_dict[token] = current_index;\n",
        "                current_index+=1;\n",
        "\n",
        "    return wordtoidx_dict, list(wordtoidx_dict.keys()), list(wordtoidx_dict.values());"
      ],
      "metadata": {
        "id": "aiUmvleiJeRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_tfidf(doc_list, word2idx_dict, encoded_doc):\n",
        "    n = len(doc_list); v = len(word2idx_dict);\n",
        "    tf = np.zeros([n,v]);\n",
        "\n",
        "    for i, tokens_idx in enumerate(encoded_doc):\n",
        "        for index in tokens_idx:\n",
        "            tf[i,index]+=1;\n",
        "\n",
        "    doc_freq = np.sum(tf>0, axis=0);\n",
        "    idf = np.log(n/doc_freq);\n",
        "\n",
        "    tf_idf = tf*idf;\n",
        "\n",
        "    return tf_idf;"
      ],
      "metadata": {
        "id": "XadTX-IdHVwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_sum(matrix, axis=0):\n",
        "    return np.sum(matrix, axis);\n",
        "\n",
        "def matrix_avg(matrix, axis=0):\n",
        "    return np.mean(matrix, axis);\n",
        "\n",
        "def matrix_quartile(matrix, quartile = 0.25):\n",
        "    return np.quantile(matrix, quartile);"
      ],
      "metadata": {
        "id": "oAtkwvvVnNkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_document(doc_list, word2idx_dict, unique_words):\n",
        "    encoded_doc = doc_list; #INITIALIZE ENCODED DOCUMENT TO ORIGINAL DOCUMENT BEFORE ENCODED TO INDEX (BECAUSE HAVE SAME SIZE)\n",
        "    row = 0;\n",
        "    for doc in doc_list:\n",
        "        tokens = word_tokenize(doc.lower());\n",
        "        tokens_idx = tokens; #INITIALIZE TOKENS_ INDEX DOCUMENT TO ORIGINAL TOKENS BEFORE ENCODED TO INDEX (BECAUSE HAVE SAME SIZE)\n",
        "        #print(f\"tokens_idx length: {len(tokens_idx)}\");\n",
        "        col = 0;\n",
        "        for token in tokens:\n",
        "            for word in unique_words:\n",
        "                #print(f\"{word} == {token}\");\n",
        "                if word == token:\n",
        "                    #print(\"EQUAL!\");\n",
        "                    #print(f\"{word} == {token}\");\n",
        "                    #print(word2idx_dict[word]);\n",
        "                    tokens_idx[col] = word2idx_dict[word];\n",
        "                    #print(tokens_idx[col])\n",
        "                    col += 1;\n",
        "        #print(tokens_idx);\n",
        "        encoded_doc[row] = tokens_idx;\n",
        "        row+=1;\n",
        "        #print(\"\\n\");\n",
        "\n",
        "    return encoded_doc;"
      ],
      "metadata": {
        "id": "Fo3P93rvliVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(threshold, tokenized_sentences, tfidf_sum):\n",
        "    selected_indices = np.array(np.where(tfidf_sum>threshold));\n",
        "    summarized_text = \"\";\n",
        "    for index in selected_indices[0]:\n",
        "        summarized_text += tokenized_sentences[index];\n",
        "    print(\"Summarized_text details:\");\n",
        "    print(\"Text length: \", str(len(summarized_text)));\n",
        "    print(\"Total selected sentences: \", str(len(selected_indices[0])));\n",
        "    return summarized_text;"
      ],
      "metadata": {
        "id": "EiNwcjbuDk7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentence = tokenize_sentence(text);"
      ],
      "metadata": {
        "id": "-Ze1NBZBbEcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordtoidx_dict, wordtoidx_keys, wordtoidx_values = mapping_wordtoidx(tokenized_sentence);"
      ],
      "metadata": {
        "id": "Tt86xMsVEfvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_doc = encode_document(tokenized_sentence, wordtoidx_dict, wordtoidx_keys);"
      ],
      "metadata": {
        "id": "m63zv32nkLSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_tfidf = calc_tfidf(tokenized_sentence, wordtoidx_dict, encoded_doc)"
      ],
      "metadata": {
        "id": "bCQSTdAOlv1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_sum = matrix_sum(text_tfidf, 1);"
      ],
      "metadata": {
        "id": "KfWlSYF-rSbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firstQ_threshold = matrix_quartile(tfidf_sum, quartile=0.25);\n",
        "avg_threshold = matrix_avg(tfidf_sum, 0);\n",
        "thirdQ_threshold = matrix_quartile(tfidf_sum, quartile=0.75);"
      ],
      "metadata": {
        "id": "EcM2GkfkvO5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_summarized = summarize_text(thirdQ_threshold, tokenized_sentence, tfidf_sum);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrJPGb8Zv-KW",
        "outputId": "9fd7310a-a177-4091-df63-4767907668e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized_text details:\n",
            "Text length:  1329\n",
            "Total selected sentences:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_summarized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "bwltKcatPC8c",
        "outputId": "7eba83a0-cc98-4498-bdf8-9e4a540507c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The UTM Ocean Thermal Energy Centre (UTM OTEC) recently hosted a face-to-face STEM (science, technology, engineering, and mathematics) workshop titled ‘Harvesting Ocean Thermal Energy & Building Your Own Seawater Fuel Cell’ at Sekolah Menengah Kebangsaan (SMK) Vivekananda in Brickfields, Kuala Lumpur.Three Science teachers who learned the STEM modules, Puan Nany Suhaila Zolkefly, Puan Afiqah Khalid, and Puan Rafizzah Jasian, became the workshop instructors for the students.Dr. Sathiabama T. Thirugnana spoke about marine renewable energy (RE), the ocean thermal energy harvesting process, and the importance of learning science and new technology in the field of engineering.In addition, Prof. Dr. Norliza gave a presentation about Institute of Electrical and Electronics Engineers (IEEE) and its benefits, standards and article publications and membership needs in the science and technology fields, which was followed by a quiz session.Both the school and UTM committee teams were pleased with the results and agreed that secondary school students should be taught about new technology development to solve engineering problems.Furthermore, they expressed a strong interest in the university’s courses and wanted to learn more about engineering and the application of computational intelligence or artificial intelligence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "2GjheF78qkhO",
        "outputId": "b9d6dcb6-fb18-42f7-cb4f-58e400a29608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The UTM Ocean Thermal Energy Centre (UTM OTEC) recently hosted a face-to-face STEM (science, technology, engineering, and mathematics) workshop titled ‘Harvesting Ocean Thermal Energy & Building Your Own Seawater Fuel Cell’ at Sekolah Menengah Kebangsaan (SMK) Vivekananda in Brickfields, Kuala Lumpur. This is in conjunction with the Minggu Sains Negara (MSN) 2022. Prior to the physical workshop at the school, a virtual ‘TOT (Train of Teachers) STEM’ workshop was held on 20th September 2022. Three Science teachers were trained to use the STEM toolkit to harvest ocean thermal energy and build their seawater fuel cells during this virtual workshop. A total of 100 science stream students attended the half-day in-person physical workshop. Three Science teachers who learned the STEM modules, Puan Nany Suhaila Zolkefly, Puan Afiqah Khalid, and Puan Rafizzah Jasian, became the workshop instructors for the students. Meanwhile, the Director of UTM-OTEC, Ts. Dr. Sathiabama T. Thirugnana spoke about marine renewable energy (RE), the ocean thermal energy harvesting process, and the importance of learning science and new technology in the field of engineering. The workshop facilitators, Prof. Dr. Norliza Mohd Noor and Dr. Pritheega Magalingam, accompanied her. In addition, Prof. Dr. Norliza gave a presentation about Institute of Electrical and Electronics Engineers (IEEE) and its benefits, standards and article publications and membership needs in the science and technology fields, which was followed by a quiz session. Students actively participated in the quiz and won valuable prizes. The students were divided into two groups, with one group receiving a talk and the other having a hands-on session simultaneously. During the second half of the workshop, the presenters and facilitators switched sessions. Students were taught on how to build their own seawater fuel cell by using appropriate electrodes, (Mg) and (Cu). Students could also correlate the topics such as periodic table, Galvanic cell and Electrolytic cell and electrochemical series. The UTM team was warmly welcomed by the principal, Mr. Selva Kumar Arumugam, and his colleagues. The principal discussed with the UTM team regarding the school students’ achievement in science subjects during the previous Sijil Pelajaran Malaysia (SPM) examination. He explained that more effort must be made to engage students in science, technology, engineering, and mathematics subjects. He also encouraged UTM to organize more STEM programmes and expressed a desire to visit UTM to gain a better understanding of the university’s environment and courses. Both the school and UTM committee teams were pleased with the results and agreed that secondary school students should be taught about new technology development to solve engineering problems. Students fully participated in the hands-on activity and question-and-answer session as a result of the workshop. Furthermore, they expressed a strong interest in the university’s courses and wanted to learn more about engineering and the application of computational intelligence or artificial intelligence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    }
  ]
}